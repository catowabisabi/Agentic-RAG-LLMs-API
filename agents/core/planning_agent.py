"""
Planning Agentï¼ˆLangGraph æ•´åˆç‰ˆï¼‰
===================================

ä½¿ç”¨ LangGraph StateGraph å¯¦ä½œæ·±åº¦æ€è€ƒèˆ‡è‡ªæˆ‘ä¿®æ­£è¿´åœˆçš„è¦åŠƒä»£ç†ã€‚

æ ¸å¿ƒç‰¹æ€§ï¼š
- ä½¿ç”¨ LangGraph å»ºç«‹ Generate â†’ Validate â†’ Refine è¿´åœˆ
- æ”¯æ´æœ€å¤š 5 æ¬¡è‡ªæˆ‘ä¿®æ­£ï¼ˆrecursion_limit=5ï¼‰
- å®Œæ•´æ•´åˆ EventBus ä¿æŒ UI å³æ™‚æ›´æ–°
- è‡ªå‹•åˆ†è§£è¤‡é›œä»»å‹™ä¸¦åˆ†é…çµ¦é©ç•¶çš„ Agents

LangGraph å·¥ä½œæµç¨‹ï¼š
1. generate_node: ç”¢ç”ŸåŸ·è¡Œè¨ˆåŠƒ
2. validate_node: é©—è­‰è¨ˆåŠƒçµæ§‹
3. conditional_edge: æ ¹æ“šé©—è­‰çµæœæ±ºå®šä¸‹ä¸€æ­¥
   - æœ‰æ•ˆ â†’ çµæŸ
   - ç„¡æ•ˆä¸” iteration < max â†’ refine_node
   - é”åˆ°ä¸Šé™ â†’ çµæŸ
4. refine_node: ä¿®æ­£è¨ˆåŠƒä¸¦å›åˆ° validate

Architecture Diagram:
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   START      â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Generate   â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     is_valid=True
    â”‚   Validate   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º END
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ is_valid=False
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Refine     â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                          â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Validate   â”‚  (loop back, max 5 iterations)
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
"""

import asyncio
import logging
from typing import Dict, Any, List, Optional, TypedDict, Annotated
from datetime import datetime

from pydantic import BaseModel, Field
from langgraph.graph import StateGraph, END

from agents.shared_services.base_agent import BaseAgent
from agents.shared_services.message_protocol import (
    AgentMessage,
    MessageType,
    MessageProtocol,
    TaskAssignment,
    ValidationResult
)

logger = logging.getLogger(__name__)


class PlanStep(BaseModel):
    """A single step in a plan"""
    step_number: int = Field(description="Step number in sequence")
    agent: str = Field(description="Agent to execute this step")
    action: str = Field(description="Action to perform")
    description: str = Field(description="Detailed description of the step")
    input_from: List[int] = Field(
        default_factory=list, 
        description="Step numbers this step depends on"
    )
    expected_output: str = Field(description="What this step should produce")


class ExecutionPlan(BaseModel):
    """Complete execution plan"""
    goal: str = Field(description="The main goal of this plan")
    reasoning: str = Field(description="Reasoning behind the plan structure")
    steps: List[PlanStep] = Field(description="Ordered list of steps")
    estimated_time: str = Field(description="Estimated time to complete")


# ============== LangGraph State Definition ==============
class PlanningState(TypedDict):
    """
    LangGraph ç‹€æ…‹å®šç¾©
    
    ç”¨æ–¼è¿½è¹¤è¦åŠƒè¿´åœˆä¸­çš„ç‹€æ…‹ï¼š
    - query: åŸå§‹æŸ¥è©¢
    - plan: ç•¶å‰åŸ·è¡Œè¨ˆåŠƒ
    - validation_result: é©—è­‰çµæœ
    - errors: éŒ¯èª¤åˆ—è¡¨
    - iteration: ç•¶å‰è¿­ä»£æ¬¡æ•¸
    - messages: ç”¨æ–¼ UI ä¸²æµçš„è¨Šæ¯åˆ—è¡¨
    """
    query: str
    agent_descriptions: str
    plan: Optional[Dict[str, Any]]
    validation_result: Optional[Dict[str, Any]]
    errors: List[str]
    iteration: int
    messages: List[str]
    is_complete: bool


# ============== Constants ==============
MAX_REFINEMENT_ITERATIONS = 5  # recursion_limit


class PlanningAgent(BaseAgent):
    """
    Planning Agent for the multi-agent system.
    
    Responsibilities:
    - Decompose complex tasks into steps
    - Create execution plans
    - Stream planning process to frontend
    """
    
    def __init__(self, agent_name: str = "planning_agent"):
        super().__init__(
            agent_name=agent_name,
            agent_role="Planning Specialist",
            agent_description="Creates step-by-step plans for complex tasks"
        )
        
        # Load prompt configuration
        self.prompt_template = self.prompt_manager.get_prompt("planning_agent")
        
        # Available agents for planning
        self.available_agents = [
            ("rag_agent", "Document retrieval and knowledge lookup"),
            ("memory_agent", "Memory storage and retrieval"),
            ("notes_agent", "Note creation and organization"),
            ("validation_agent", "Data and response validation"),
            ("thinking_agent", "Deep reasoning and analysis"),
            ("data_agent", "Data processing and transformation"),
            ("tool_agent", "External tool and API execution"),
            ("summarize_agent", "Summarization and condensation"),
            ("translate_agent", "Language translation"),
            ("calculation_agent", "Mathematical calculations")
        ]
        
        # å»ºç«‹ LangGraph
        self.planning_graph = self._build_planning_graph()
        
        logger.info("PlanningAgent initialized with LangGraph (recursion_limit=%d)", 
                    MAX_REFINEMENT_ITERATIONS)
    
    # ============== LangGraph å»ºæ§‹ ==============
    def _build_planning_graph(self) -> StateGraph:
        """
        å»ºç«‹ LangGraph StateGraph
        
        ç¯€é»ï¼š
        - generate: ç”¢ç”ŸåŸ·è¡Œè¨ˆåŠƒ
        - validate: é©—è­‰è¨ˆåŠƒ
        - refine: ä¿®æ­£è¨ˆåŠƒ
        
        é‚Šï¼š
        - START â†’ generate
        - generate â†’ validate
        - validate â†’ END (if valid)
        - validate â†’ refine (if invalid and iteration < max)
        - validate â†’ END (if iteration >= max)
        - refine â†’ validate (loop back)
        """
        # å»ºç«‹ StateGraph
        workflow = StateGraph(PlanningState)
        
        # æ·»åŠ ç¯€é»
        workflow.add_node("generate", self._graph_generate)
        workflow.add_node("validate", self._graph_validate)
        workflow.add_node("refine", self._graph_refine)
        
        # è¨­å®šå…¥å£é»
        workflow.set_entry_point("generate")
        
        # æ·»åŠ é‚Š
        workflow.add_edge("generate", "validate")
        workflow.add_conditional_edges(
            "validate",
            self._should_continue,
            {
                "end": END,
                "refine": "refine"
            }
        )
        workflow.add_edge("refine", "validate")
        
        return workflow.compile()
    
    async def _graph_generate(self, state: PlanningState) -> Dict[str, Any]:
        """
        LangGraph ç¯€é»ï¼šç”¢ç”ŸåŸ·è¡Œè¨ˆåŠƒ
        """
        query = state["query"]
        agent_descriptions = state["agent_descriptions"]
        
        try:
            plan = await self.llm_service.generate_with_structured_output(
                prompt_key="planning_agent",
                output_schema=ExecutionPlan,
                variables={
                    "query": query,
                    "agents": agent_descriptions
                }
            )
            
            plan_dict = {
                "goal": plan.goal,
                "reasoning": plan.reasoning,
                "steps": [step.model_dump() for step in plan.steps],
                "estimated_time": plan.estimated_time
            }
            
            return {
                "plan": plan_dict,
                "messages": state["messages"] + [f"ğŸ“Œ Generated plan: {plan.goal}"],
                "iteration": state["iteration"]
            }
            
        except Exception as e:
            logger.error(f"Error generating plan: {e}")
            return {
                "plan": None,
                "errors": [str(e)],
                "messages": state["messages"] + [f"âŒ Generation error: {e}"],
                "is_complete": True
            }
    
    async def _graph_validate(self, state: PlanningState) -> Dict[str, Any]:
        """
        LangGraph ç¯€é»ï¼šé©—è­‰è¨ˆåŠƒ
        """
        plan = state["plan"]
        
        if not plan:
            return {
                "validation_result": {"is_valid": False, "errors": ["No plan generated"]},
                "errors": ["No plan generated"],
                "is_complete": True
            }
        
        errors = []
        warnings = []
        valid_agents = [name for name, _ in self.available_agents]
        
        steps = plan.get("steps", [])
        
        for step in steps:
            agent = step.get("agent", "")
            step_num = step.get("step_number", 0)
            
            if agent not in valid_agents:
                errors.append(f"Step {step_num}: Unknown agent '{agent}'")
            
            for dep in step.get("input_from", []):
                if dep >= step_num:
                    errors.append(f"Step {step_num}: Invalid dependency on future step {dep}")
                if dep < 1:
                    errors.append(f"Step {step_num}: Invalid step reference {dep}")
        
        if len(steps) == 0:
            errors.append("Plan has no steps")
        
        if len(steps) > 10:
            warnings.append("Plan has many steps, consider simplifying")
        
        validation_result = {
            "is_valid": len(errors) == 0,
            "errors": errors,
            "warnings": warnings
        }
        
        iteration = state["iteration"] + 1
        new_messages = state["messages"] + [
            f"ğŸ” Validation iteration {iteration}: {'âœ… Valid' if validation_result['is_valid'] else f'âŒ {len(errors)} errors'}"
        ]
        
        return {
            "validation_result": validation_result,
            "errors": errors,
            "iteration": iteration,
            "messages": new_messages
        }
    
    async def _graph_refine(self, state: PlanningState) -> Dict[str, Any]:
        """
        LangGraph ç¯€é»ï¼šä¿®æ­£è¨ˆåŠƒ
        """
        plan = state["plan"]
        errors = state["errors"]
        agent_descriptions = state["agent_descriptions"]
        
        refine_prompt = f"""Fix these errors in the execution plan:

Current Plan:
Goal: {plan.get("goal", "")}
Steps: {str(plan.get("steps", []))}

Errors to fix:
{chr(10).join(errors)}

Available Agents:
{agent_descriptions}

Create a corrected plan."""
        
        try:
            refined = await self.llm_service.generate_with_structured_output(
                prompt_key="planning_agent",
                output_schema=ExecutionPlan,
                user_input=refine_prompt
            )
            
            refined_dict = {
                "goal": refined.goal,
                "reasoning": refined.reasoning,
                "steps": [step.model_dump() for step in refined.steps],
                "estimated_time": refined.estimated_time
            }
            
            return {
                "plan": refined_dict,
                "messages": state["messages"] + [f"ğŸ”§ Refined plan (iteration {state['iteration']})"]
            }
            
        except Exception as e:
            logger.error(f"Error refining plan: {e}")
            return {
                "messages": state["messages"] + [f"âš ï¸ Refinement failed: {e}"]
            }
    
    def _should_continue(self, state: PlanningState) -> str:
        """
        æ¢ä»¶é‚Šï¼šæ±ºå®šæ˜¯å¦ç¹¼çºŒè¿´åœˆ
        
        è¿”å›ï¼š
        - "end": è¨ˆåŠƒæœ‰æ•ˆæˆ–é”åˆ°è¿­ä»£ä¸Šé™
        - "refine": è¨ˆåŠƒç„¡æ•ˆä¸”æœªé”ä¸Šé™
        """
        validation = state.get("validation_result", {})
        iteration = state.get("iteration", 0)
        
        # å·²å®Œæˆï¼ˆéŒ¯èª¤æˆ–æˆåŠŸï¼‰
        if state.get("is_complete", False):
            return "end"
        
        # è¨ˆåŠƒæœ‰æ•ˆ
        if validation.get("is_valid", False):
            return "end"
        
        # é”åˆ°è¿­ä»£ä¸Šé™
        if iteration >= MAX_REFINEMENT_ITERATIONS:
            logger.warning(f"Reached max refinement iterations ({MAX_REFINEMENT_ITERATIONS})")
            return "end"
        
        # ç¹¼çºŒä¿®æ­£
        return "refine"
    
    async def process_task(self, task: TaskAssignment) -> Any:
        """Process a planning task"""
        task_type = task.task_type
        
        if task_type == "create_plan":
            return await self._create_plan_for_manager(task)
        elif task_type == "create_plan_langgraph":
            return await self._create_plan_with_langgraph(task)
        elif task_type == "refine_plan":
            return await self._refine_plan(task)
        else:
            return await self._create_plan_for_manager(task)
    
    async def _create_plan_for_manager(self, task: TaskAssignment) -> Dict[str, Any]:
        """
        Create execution plan for Manager Agent V2.
        
        Returns plan in Todo format that Manager can execute directly.
        """
        query = task.input_data.get("query", task.description)
        context = task.input_data.get("context", "")
        user_context = task.input_data.get("user_context", "")
        available_agents = task.input_data.get("available_agents", [])
        
        # Agent descriptions
        agent_desc = "\n".join([
            f"- {name}: {desc}" for name, desc in self.available_agents
            if name in available_agents or not available_agents
        ])
        
        context_section = f"\nContext: {context}" if context else ""
        user_context_section = f"\nUser preferences: {user_context}" if user_context else ""
        
        plan_prompt = f"""You are a task planner. Analyze this query and create an execution plan.

Query: {query}
{context_section}
{user_context_section}

Available Agents:
{agent_desc}

Create a plan with these guidelines:
1. Break into minimal steps (1-5 steps usually)
2. Each step should have: agent, task_type, title, description
3. Specify dependencies if steps need to run in order
4. For simple queries, just 1 step is fine

Respond in JSON format:
{{
    "goal": "main goal",
    "strategy": "brief strategy",
    "complexity": "simple|medium|complex",
    "todos": [
        {{
            "title": "step title",
            "description": "what to do",
            "agent": "agent_name",
            "task_type": "task type (e.g., analyze, calculate, translate)",
            "priority": "high|medium|low",
            "depends_on": [],
            "input_data": {{}}
        }}
    ]
}}"""
        
        # [NO FALLBACK] Errors propagate for testing visibility
        result = await self.llm_service.generate(
            prompt_key="planning_agent",
            user_input=plan_prompt
        )
        
        content = result.get("content", "")
        
        # Parse JSON
        import json
        import re
        json_match = re.search(r'\{[\s\S]*\}', content)
        if json_match:
            plan_data = json.loads(json_match.group())
            
            # Add query to each todo's input_data
            for todo in plan_data.get("todos", []):
                if "input_data" not in todo:
                    todo["input_data"] = {}
                todo["input_data"]["query"] = query
                todo["input_data"]["user_context"] = user_context
            
            return {
                "success": True,
                "goal": plan_data.get("goal", query),
                "strategy": plan_data.get("strategy", "Direct execution"),
                "complexity": plan_data.get("complexity", "simple"),
                "todos": plan_data.get("todos", [])
            }
        else:
            # [NO FALLBACK] Plan creation must succeed - errors propagate for testing
            raise ValueError(f"LLM did not return valid plan data for query: {query[:50]}...")
    
    # [REMOVED] _create_fallback_plan() method - no longer used as fallback is disabled
    
    async def _create_plan_with_langgraph(self, task: TaskAssignment) -> Dict[str, Any]:
        """
        ä½¿ç”¨ LangGraph å»ºç«‹åŸ·è¡Œè¨ˆåŠƒ
        
        é€é StateGraph å¯¦ç¾ Generate â†’ Validate â†’ Refine è¿´åœˆï¼Œ
        æ”¯æ´æœ€å¤š MAX_REFINEMENT_ITERATIONS æ¬¡è‡ªæˆ‘ä¿®æ­£ã€‚
        """
        original_task = task.input_data.get("original_task", {})
        query = original_task.get("description", task.description)
        
        # Stream initial thinking to frontend
        await self.stream_to_frontend(
            f"ğŸ“‹ Analyzing task with LangGraph: {query[:100]}...\n", 
            0
        )
        
        agent_descriptions = "\n".join([
            f"- {name}: {desc}" for name, desc in self.available_agents
        ])
        
        # åˆå§‹åŒ– LangGraph ç‹€æ…‹
        initial_state: PlanningState = {
            "query": query,
            "agent_descriptions": agent_descriptions,
            "plan": None,
            "validation_result": None,
            "errors": [],
            "iteration": 0,
            "messages": [],
            "is_complete": False
        }
        
        await self.stream_to_frontend(
            "ğŸ” Starting LangGraph planning workflow...\n", 
            1
        )
        
        try:
            # åŸ·è¡Œ LangGraphï¼ˆä½¿ç”¨ astream ä¿æŒ UI æ›´æ–°ï¼‰
            final_state = None
            step_count = 0
            
            async for state in self.planning_graph.astream(initial_state):
                step_count += 1
                
                # å–å¾—ç•¶å‰ç¯€é»çš„ç‹€æ…‹
                for node_name, node_state in state.items():
                    if "messages" in node_state:
                        for msg in node_state.get("messages", [])[-1:]:
                            await self.stream_to_frontend(f"  [{node_name}] {msg}\n", step_count)
                    
                    final_state = node_state
            
            # æª¢æŸ¥æœ€çµ‚çµæœ
            if final_state and final_state.get("plan"):
                plan_dict = final_state["plan"]
                validation = final_state.get("validation_result", {})
                
                # ä¸²æµè¨ˆåŠƒåˆ°å‰ç«¯
                await self._stream_plan_dict(plan_dict)
                
                result = {
                    "success": True,
                    "plan": plan_dict,
                    "validation": validation,
                    "iterations": final_state.get("iteration", 1),
                    "langgraph": True
                }
                
                # ç™¼é€è¨ˆåŠƒåˆ° Manager
                plan_obj = ExecutionPlan(
                    goal=plan_dict["goal"],
                    reasoning=plan_dict["reasoning"],
                    steps=[PlanStep(**s) for s in plan_dict["steps"]],
                    estimated_time=plan_dict["estimated_time"]
                )
                await self._send_plan_to_manager(plan_obj, original_task)
                
                return result
            else:
                errors = final_state.get("errors", ["Unknown error"]) if final_state else ["No state returned"]
                return {
                    "success": False,
                    "error": "; ".join(errors),
                    "langgraph": True
                }
                
        except Exception as e:
            logger.error(f"LangGraph error: {e}")
            await self.stream_to_frontend(f"âŒ LangGraph error: {e}\n", -1)
            return {
                "success": False,
                "error": str(e),
                "langgraph": True
            }
    
    async def _stream_plan_dict(self, plan: Dict[str, Any]):
        """Stream plan dictionary to frontend"""
        await self.stream_to_frontend(
            f"\nğŸ“Œ Goal: {plan.get('goal', 'N/A')}\n",
            100
        )
        
        await self.stream_to_frontend(
            f"ğŸ’­ Reasoning: {plan.get('reasoning', 'N/A')}\n\n",
            101
        )
        
        await self.stream_to_frontend(
            "ğŸ“ Execution Steps:\n",
            102
        )
        
        for i, step in enumerate(plan.get("steps", [])):
            step_text = (
                f"\n  Step {step.get('step_number', i+1)}: [{step.get('agent', 'unknown')}]\n"
                f"  Action: {step.get('action', 'N/A')}\n"
                f"  Details: {step.get('description', 'N/A')}\n"
                f"  Expected: {step.get('expected_output', 'N/A')}\n"
            )
            if step.get("input_from"):
                step_text += f"  Depends on: Steps {step['input_from']}\n"
            
            await self.stream_to_frontend(step_text, 103 + i)
            await asyncio.sleep(0.1)
        
        await self.stream_to_frontend(
            f"\nâ±ï¸ Estimated time: {plan.get('estimated_time', 'N/A')}\n",
            200
        )

    async def _create_plan(self, task: TaskAssignment) -> Dict[str, Any]:
        """Create an execution plan for a complex task"""
        original_task = task.input_data.get("original_task", {})
        query = original_task.get("description", task.description)
        
        # Stream initial thinking to frontend
        await self.stream_to_frontend(
            f"ğŸ“‹ Analyzing task: {query[:100]}...\n", 
            0
        )
        
        agent_descriptions = "\n".join([
            f"- {name}: {desc}" for name, desc in self.available_agents
        ])
        
        # Stream planning process
        await self.stream_to_frontend(
            "ğŸ” Identifying required agents and steps...\n", 
            1
        )
        
        try:
            plan = await self.llm_service.generate_with_structured_output(
                prompt_key="planning_agent",
                output_schema=ExecutionPlan,
                variables={
                    "query": query,
                    "agents": agent_descriptions
                }
            )
            
            # Stream the plan to frontend
            await self._stream_plan(plan)
            
            # Validate the plan
            validation = await self._validate_plan(plan)
            
            if not validation["is_valid"]:
                # Refine the plan
                plan = await self._refine_plan_internal(plan, validation["errors"])
            
            result = {
                "success": True,
                "plan": {
                    "goal": plan.goal,
                    "reasoning": plan.reasoning,
                    "steps": [step.model_dump() for step in plan.steps],
                    "estimated_time": plan.estimated_time
                },
                "validation": validation
            }
            
            # Send plan to manager for execution
            await self._send_plan_to_manager(plan, original_task)
            
            return result
            
        except Exception as e:
            logger.error(f"Error creating plan: {e}")
            await self.stream_to_frontend(f"âŒ Error creating plan: {e}\n", -1)
            return {
                "success": False,
                "error": str(e)
            }
    
    async def _stream_plan(self, plan: ExecutionPlan):
        """Stream the plan to frontend"""
        await self.stream_to_frontend(
            f"\nğŸ“Œ Goal: {plan.goal}\n",
            2
        )
        
        await self.stream_to_frontend(
            f"ğŸ’­ Reasoning: {plan.reasoning}\n\n",
            3
        )
        
        await self.stream_to_frontend(
            "ğŸ“ Execution Steps:\n",
            4
        )
        
        for i, step in enumerate(plan.steps):
            step_text = (
                f"\n  Step {step.step_number}: [{step.agent}]\n"
                f"  Action: {step.action}\n"
                f"  Details: {step.description}\n"
                f"  Expected: {step.expected_output}\n"
            )
            if step.input_from:
                step_text += f"  Depends on: Steps {step.input_from}\n"
            
            await self.stream_to_frontend(step_text, 5 + i)
            await asyncio.sleep(0.2)  # Small delay for visual effect
        
        await self.stream_to_frontend(
            f"\nâ±ï¸ Estimated time: {plan.estimated_time}\n",
            100
        )
    
    async def _validate_plan(self, plan: ExecutionPlan) -> Dict[str, Any]:
        """Validate the plan structure"""
        errors = []
        warnings = []
        
        valid_agents = [name for name, _ in self.available_agents]
        
        for step in plan.steps:
            if step.agent not in valid_agents:
                errors.append(f"Step {step.step_number}: Unknown agent '{step.agent}'")
            
            for dep in step.input_from:
                if dep >= step.step_number:
                    errors.append(
                        f"Step {step.step_number}: Invalid dependency on future step {dep}"
                    )
                if dep < 1:
                    errors.append(
                        f"Step {step.step_number}: Invalid step reference {dep}"
                    )
        
        if len(plan.steps) == 0:
            errors.append("Plan has no steps")
        
        if len(plan.steps) > 10:
            warnings.append("Plan has many steps, consider simplifying")
        
        return {
            "is_valid": len(errors) == 0,
            "errors": errors,
            "warnings": warnings
        }
    
    async def _refine_plan(self, task: TaskAssignment) -> Dict[str, Any]:
        """Refine an existing plan based on feedback"""
        original_plan = task.input_data.get("plan", {})
        feedback = task.input_data.get("feedback", "")
        
        agent_descriptions = "\n".join([
            f"- {name}: {desc}" for name, desc in self.available_agents
        ])
        
        refine_prompt = f"""Refine this execution plan based on the feedback.

Original Plan:
{str(original_plan)}

Feedback:
{feedback}

Available Agents:
{agent_descriptions}

Create an improved plan that addresses the feedback."""
        
        try:
            plan = await self.llm_service.generate_with_structured_output(
                prompt_key="planning_agent",
                output_schema=ExecutionPlan,
                user_input=refine_prompt
            )
            
            return {
                "success": True,
                "plan": {
                    "goal": plan.goal,
                    "reasoning": plan.reasoning,
                    "steps": [step.model_dump() for step in plan.steps],
                    "estimated_time": plan.estimated_time
                }
            }
            
        except Exception as e:
            logger.error(f"Error refining plan: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    async def _refine_plan_internal(
        self, 
        plan: ExecutionPlan, 
        errors: List[str]
    ) -> ExecutionPlan:
        """Internal plan refinement based on validation errors"""
        agent_descriptions = "\n".join([
            f"- {name}: {desc}" for name, desc in self.available_agents
        ])
        
        refine_prompt = f"""Fix these errors in the execution plan:

Current Plan:
Goal: {plan.goal}
Steps: {str([s.model_dump() for s in plan.steps])}

Errors to fix:
{chr(10).join(errors)}

Available Agents:
{agent_descriptions}

Create a corrected plan."""
        
        # [NO FALLBACK] Refinement - errors propagate for testing
        refined = await self.llm_service.generate_with_structured_output(
            prompt_key="planning_agent",
            output_schema=ExecutionPlan,
            user_input=refine_prompt
        )
        return refined
    
    async def _send_plan_to_manager(
        self, 
        plan: ExecutionPlan, 
        original_task: Dict
    ):
        """Send the completed plan to manager for execution"""
        message = AgentMessage(
            type=MessageType.TASK_RESULT,
            source_agent=self.agent_name,
            target_agent="manager_agent",
            content={
                "result_type": "execution_plan",
                "plan": {
                    "goal": plan.goal,
                    "steps": [step.model_dump() for step in plan.steps]
                },
                "original_task": original_task
            }
        )
        
        await self.ws_manager.send_to_agent(message)
