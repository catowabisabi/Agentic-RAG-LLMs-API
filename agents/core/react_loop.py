"""
ReAct Loop Engine (Enhanced with PEV and Self-Correction)
==========================================================

å¯¦ç¾ Reason + Act è¿­ä»£æ¨ç†å¾ªç’°ï¼Œè®“ Agent èƒ½å¤ ï¼š
1. æ€è€ƒï¼ˆThinkï¼‰: åˆ†æç•¶å‰ç‹€æ…‹ï¼Œæ±ºå®šä¸‹ä¸€æ­¥è¡Œå‹•
2. è¡Œå‹•ï¼ˆActï¼‰: åŸ·è¡Œæœå°‹ã€èª¿ç”¨å·¥å…·ç­‰
3. è§€å¯Ÿï¼ˆObserveï¼‰: ç²å–è¡Œå‹•çµæœ
4. é©—è­‰ï¼ˆVerify - PEVï¼‰: è©•ä¼°çµæœå“è³ª
5. åæ€ï¼ˆReflectï¼‰: è©•ä¼°çµæœæ˜¯å¦è¶³å¤ å›ç­”å•é¡Œï¼ŒSelf-Correction

åƒè€ƒ: 
- app_docs/Agentic-Rag-Examples/03_ReAct.ipynb
- app_docs/Agentic-Rag-Examples/06_PEV.ipynb
- example/01/05-agentic-rag/README.md
"""

import asyncio
import logging
from typing import Dict, Any, List, Optional, Callable, Awaitable
from datetime import datetime
from enum import Enum
from pydantic import BaseModel, Field

from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

from config.config import Config

logger = logging.getLogger(__name__)


class ActionType(str, Enum):
    """å¯åŸ·è¡Œçš„è¡Œå‹•é¡å‹"""
    SEARCH = "search"           # æœå°‹çŸ¥è­˜åº« (RAG)
    WEB_SEARCH = "web_search"   # ç¶²çµ¡æœå°‹
    CALCULATE = "calculate"     # è¨ˆç®—
    FINAL_ANSWER = "final_answer"  # çµ¦å‡ºæœ€çµ‚ç­”æ¡ˆ
    CLARIFY = "clarify"         # éœ€è¦ç”¨æˆ¶æ¾„æ¸…
    REFINE_QUERY = "refine_query"  # æ”¹å¯«æŸ¥è©¢ (Self-Correction)
    VERIFY = "verify"           # é©—è­‰è³‡è¨Š


class VerificationResult(BaseModel):
    """PEV é©—è­‰çµæœ"""
    is_valid: bool = Field(description="è³‡è¨Šæ˜¯å¦æœ‰æ•ˆ")
    quality_score: float = Field(default=0.5, description="å“è³ªåˆ†æ•¸ 0-1")
    issues: List[str] = Field(default_factory=list, description="ç™¼ç¾çš„å•é¡Œ")
    should_retry: bool = Field(default=False, description="æ˜¯å¦éœ€è¦é‡è©¦")
    retry_strategy: Optional[str] = Field(default=None, description="é‡è©¦ç­–ç•¥")


class ThoughtAction(BaseModel):
    """æ€è€ƒçµæœå’Œæ±ºå®šçš„è¡Œå‹•"""
    thought: str = Field(description="ç•¶å‰çš„æ€è€ƒå…§å®¹")
    action: ActionType = Field(description="æ±ºå®šæ¡å–çš„è¡Œå‹•")
    action_input: str = Field(description="è¡Œå‹•çš„è¼¸å…¥åƒæ•¸")
    confidence: float = Field(default=0.5, description="å°ç•¶å‰æ–¹å‘çš„ä¿¡å¿ƒ (0-1)")
    self_assessment: str = Field(default="", description="è‡ªæˆ‘è©•ä¼°ï¼šæˆ‘èƒ½è™•ç†é€™å€‹å•é¡Œå—?")


class Observation(BaseModel):
    """è§€å¯Ÿçµæœ"""
    content: str = Field(description="è§€å¯Ÿåˆ°çš„å…§å®¹")
    sources: List[Dict[str, Any]] = Field(default_factory=list, description="ä¾†æº")
    success: bool = Field(default=True, description="è¡Œå‹•æ˜¯å¦æˆåŠŸ")
    quality_score: float = Field(default=0.5, description="å“è³ªè©•åˆ† 0-1")


class ReActStep(BaseModel):
    """ä¸€å€‹ ReAct æ­¥é©Ÿ (å¢åŠ é©—è­‰çµæœ)"""
    step_number: int
    thought: str
    action: ActionType
    action_input: str
    observation: Optional[str] = None
    verification: Optional[VerificationResult] = None
    timestamp: str = Field(default_factory=lambda: datetime.now().isoformat())


class ReActResult(BaseModel):
    """ReAct å¾ªç’°çš„æœ€çµ‚çµæœ"""
    final_answer: str
    steps: List[ReActStep]
    total_iterations: int
    sources: List[Dict[str, Any]]
    success: bool
    reasoning_trace: str  # å®Œæ•´æ¨ç†è»Œè·¡
    verification_passed: bool = Field(default=True, description="æ˜¯å¦é€šé PEV é©—è­‰")
    strategy_used: str = Field(default="react", description="ä½¿ç”¨çš„ç­–ç•¥")


class ReActLoop:
    """
    ReAct å¾ªç’°å¼•æ“ (Enhanced with PEV and Self-Correction)
    
    å¯¦ç¾ Think -> Act -> Observe -> Verify -> Reflect çš„è¿­ä»£æ¨ç†
    
    é—œéµæ”¹é€²ï¼š
    1. RAG ä½œç‚º Tool - å‹•æ…‹æ±ºå®šæ˜¯å¦ä½¿ç”¨
    2. PEV é©—è­‰ - æ¯å€‹æ­¥é©Ÿéƒ½é©—è­‰çµæœ
    3. Self-Correction - å¤±æ•—æ™‚è‡ªå‹•èª¿æ•´ç­–ç•¥
    4. Metacognitive Assessment - è‡ªæˆ‘è©•ä¼°èƒ½åŠ›é‚Šç•Œ
    """
    
    def __init__(
        self,
        max_iterations: int = 5,
        verification_threshold: float = 0.6,
        max_retries_per_step: int = 2,
        on_step_callback: Optional[Callable[[ReActStep], Awaitable[None]]] = None
    ):
        self.config = Config()
        self.llm = ChatOpenAI(
            model=self.config.DEFAULT_MODEL,
            temperature=0.3,
            api_key=self.config.OPENAI_API_KEY
        )
        self.max_iterations = max_iterations
        self.verification_threshold = verification_threshold
        self.max_retries_per_step = max_retries_per_step
        self.on_step_callback = on_step_callback
        
        # å·¥å…·è¨»å†Šè¡¨
        self.tools: Dict[ActionType, Callable] = {}
        
        # å¤±æ•—è¨˜éŒ„ (ç”¨æ–¼ Self-Correction)
        self.failed_attempts: List[Dict[str, Any]] = []
        
    def register_tool(self, action_type: ActionType, tool_func: Callable):
        """è¨»å†Šä¸€å€‹å·¥å…·"""
        self.tools[action_type] = tool_func
        logger.info(f"Registered tool: {action_type.value}")
    
    async def verify_observation(
        self,
        query: str,
        observation: Observation,
        step_context: str
    ) -> VerificationResult:
        """
        PEV é©—è­‰å™¨ï¼šæª¢æŸ¥è§€å¯Ÿçµæœçš„å“è³ªå’Œæœ‰æ•ˆæ€§
        
        åƒè€ƒ: 06_PEV.ipynb
        """
        prompt = ChatPromptTemplate.from_template(
            """You are a verification agent (PEV - Plan, Execute, Verify).
Your job is to verify if the tool output is valid and useful for answering the question.

Original Question: {query}

Tool Output to Verify:
{observation}

Step Context:
{step_context}

Check for:
1. Is this a valid result or an error message?
2. Does the result contain relevant information for the question?
3. Is the information complete enough to proceed?
4. Are there any inconsistencies or red flags?

If the result is an error or insufficient:
- Suggest a retry strategy: "refine_query" (try different search terms), 
  "different_source" (try another tool), "decompose" (break into simpler questions)

Respond in JSON format:
{{
    "is_valid": true/false,
    "quality_score": 0.0-1.0,
    "issues": ["issue1", "issue2"],
    "should_retry": true/false,
    "retry_strategy": "refine_query|different_source|decompose|null"
}}
"""
        )
        
        try:
            chain = prompt | self.llm
            result = await chain.ainvoke({
                "query": query,
                "observation": observation.content[:2000],
                "step_context": step_context[:1000]
            })
            
            response = result.content if hasattr(result, 'content') else str(result)
            
            import json
            response = response.strip()
            if response.startswith("```json"):
                response = response[7:]
            if response.startswith("```"):
                response = response[3:]
            if response.endswith("```"):
                response = response[:-3]
            
            data = json.loads(response.strip())
            
            return VerificationResult(
                is_valid=data.get("is_valid", True),
                quality_score=float(data.get("quality_score", 0.5)),
                issues=data.get("issues", []),
                should_retry=data.get("should_retry", False),
                retry_strategy=data.get("retry_strategy")
            )
            
        except Exception as e:
            logger.error(f"Verification error: {e}")
            # é»˜èªé€šéï¼Œé¿å…é˜»å¡æµç¨‹
            return VerificationResult(
                is_valid=True,
                quality_score=0.5,
                issues=[f"Verification error: {e}"]
            )
    
    async def self_correct(
        self,
        query: str,
        failed_action: ActionType,
        failed_input: str,
        failure_reason: str,
        retry_strategy: Optional[str]
    ) -> ThoughtAction:
        """
        Self-Correction: ç•¶æ­¥é©Ÿå¤±æ•—æ™‚ï¼Œç”Ÿæˆæ–°çš„ç­–ç•¥
        
        åƒè€ƒ: 06_PEV.ipynb çš„ re-planning æ©Ÿåˆ¶
        """
        prompt = ChatPromptTemplate.from_template(
            """You are a self-correcting agent. A previous action failed and you need to adapt.

Original Question: {query}

Failed Action: {failed_action}({failed_input})
Failure Reason: {failure_reason}

Suggested Retry Strategy: {retry_strategy}

Previous Failed Attempts:
{failed_attempts}

Generate a NEW action that avoids the previous mistakes:
1. If "refine_query": Try different search terms or phrasing
2. If "different_source": Use a different tool or approach
3. If "decompose": Break the question into simpler parts

Do NOT repeat the same failed query.

Respond in JSON:
{{
    "thought": "reasoning about the correction",
    "action": "search|calculate|final_answer|clarify",
    "action_input": "new input that avoids previous mistakes",
    "confidence": 0.0-1.0,
    "self_assessment": "assessment of ability to handle this"
}}
"""
        )
        
        failed_attempts_str = "\n".join([
            f"- {a['action']}: {a['input'][:50]}... -> {a['reason']}"
            for a in self.failed_attempts[-3:]  # æœ€è¿‘3æ¬¡å¤±æ•—
        ])
        
        try:
            chain = prompt | self.llm
            result = await chain.ainvoke({
                "query": query,
                "failed_action": failed_action.value,
                "failed_input": failed_input[:200],
                "failure_reason": failure_reason,
                "retry_strategy": retry_strategy or "refine_query",
                "failed_attempts": failed_attempts_str or "None"
            })
            
            response = result.content if hasattr(result, 'content') else str(result)
            
            import json
            response = response.strip()
            if response.startswith("```json"):
                response = response[7:]
            if response.startswith("```"):
                response = response[3:]
            if response.endswith("```"):
                response = response[:-3]
            
            data = json.loads(response.strip())
            
            action_str = data.get("action", "search").lower()
            action_map = {
                "search": ActionType.SEARCH,
                "final_answer": ActionType.FINAL_ANSWER,
                "clarify": ActionType.CLARIFY,
                "web_search": ActionType.WEB_SEARCH,
                "calculate": ActionType.CALCULATE,
                "refine_query": ActionType.REFINE_QUERY
            }
            
            return ThoughtAction(
                thought=data.get("thought", "Attempting correction"),
                action=action_map.get(action_str, ActionType.SEARCH),
                action_input=data.get("action_input", query),
                confidence=float(data.get("confidence", 0.4)),
                self_assessment=data.get("self_assessment", "")
            )
            
        except Exception as e:
            logger.error(f"Self-correction error: {e}")
            # æœ€å¾Œæ‰‹æ®µï¼šç›´æ¥å›ç­”
            return ThoughtAction(
                thought=f"Self-correction failed: {e}. Will attempt direct answer.",
                action=ActionType.FINAL_ANSWER,
                action_input="I apologize, but I encountered difficulties processing your question. Could you please rephrase it?",
                confidence=0.2,
                self_assessment="Low confidence due to repeated failures"
            )
    
    async def think(
        self,
        query: str,
        context: str,
        previous_steps: List[ReActStep]
    ) -> ThoughtAction:
        """
        æ€è€ƒæ­¥é©Ÿï¼šåˆ†æç•¶å‰ç‹€æ…‹ï¼Œæ±ºå®šä¸‹ä¸€æ­¥è¡Œå‹•
        
        å¢å¼·ï¼šåŠ å…¥ Metacognitive è‡ªæˆ‘è©•ä¼°
        """
        # æ§‹å»ºæ­·å²è»Œè·¡
        history = ""
        for step in previous_steps:
            history += f"\nStep {step.step_number}:\n"
            history += f"  Thought: {step.thought}\n"
            history += f"  Action: {step.action.value}({step.action_input})\n"
            if step.observation:
                history += f"  Observation: {step.observation[:500]}...\n"
            if step.verification:
                history += f"  Verification: valid={step.verification.is_valid}, score={step.verification.quality_score}\n"
        
        # æ§‹å»ºå¤±æ•—è¨˜éŒ„
        failed_info = ""
        if self.failed_attempts:
            failed_info = "Failed attempts to avoid:\n" + "\n".join([
                f"- {a['input'][:50]}..."
                for a in self.failed_attempts[-3:]
            ])
        
        prompt = ChatPromptTemplate.from_template(
            """You are a reasoning agent with self-awareness. Analyze the question and decide your next action.

Question: {query}

Current Knowledge Context:
{context}

Previous Steps:
{history}

{failed_info}

Available Actions:
1. search: Search the knowledge base for more information. Input: search query string
2. final_answer: Provide the final answer if you have enough information. Input: your complete answer
3. clarify: Ask for clarification if the question is unclear. Input: clarification question
4. calculate: Perform a calculation. Input: the calculation expression
5. refine_query: Refine a previous search query that didn't work well. Input: improved query

**Metacognitive Self-Assessment:**
Before deciding, ask yourself:
- Do I have enough information to answer confidently?
- Is this within my knowledge capabilities?
- Should I search for more information or can I answer directly?
- If previous searches failed, how should I adjust my approach?

Think step by step:
1. What do I know so far?
2. What do I still need to find out?
3. Is the current context sufficient to answer the question?
4. Can I answer this confidently, or do I need more information?

If you have gathered enough information to fully answer the question, use final_answer.
If you need more information, use search with a specific query.
If previous searches didn't help, try refine_query with different terms.

Respond in this exact JSON format:
{{
    "thought": "your reasoning here",
    "action": "search|final_answer|clarify|calculate|refine_query",
    "action_input": "the input for your chosen action",
    "confidence": 0.0-1.0,
    "self_assessment": "brief assessment: can I handle this? what are my limitations here?"
}}
"""
        )
        
        try:
            chain = prompt | self.llm
            result = await chain.ainvoke({
                "query": query,
                "context": context[:3000] if context else "No context yet.",
                "history": history if history else "No previous steps.",
                "failed_info": failed_info
            })
            
            response = result.content if hasattr(result, 'content') else str(result)
            
            # è§£æ JSON å›æ‡‰
            import json
            # æ¸…ç†å¯èƒ½çš„ markdown æ¨™è¨˜
            response = response.strip()
            if response.startswith("```json"):
                response = response[7:]
            if response.startswith("```"):
                response = response[3:]
            if response.endswith("```"):
                response = response[:-3]
            
            data = json.loads(response.strip())
            
            action_str = data.get("action", "search").lower()
            action_map = {
                "search": ActionType.SEARCH,
                "final_answer": ActionType.FINAL_ANSWER,
                "clarify": ActionType.CLARIFY,
                "web_search": ActionType.WEB_SEARCH,
                "calculate": ActionType.CALCULATE,
                "refine_query": ActionType.REFINE_QUERY,
                "verify": ActionType.VERIFY
            }
            
            return ThoughtAction(
                thought=data.get("thought", ""),
                action=action_map.get(action_str, ActionType.SEARCH),
                action_input=data.get("action_input", query),
                confidence=float(data.get("confidence", 0.5)),
                self_assessment=data.get("self_assessment", "")
            )
            
        except Exception as e:
            logger.error(f"Think step error: {e}")
            # ç™¼ç”ŸéŒ¯èª¤æ™‚ï¼Œå˜—è©¦ç›´æ¥å›ç­”
            return ThoughtAction(
                thought=f"Error during reasoning: {e}",
                action=ActionType.FINAL_ANSWER,
                action_input="I encountered an issue while processing your question. Please try rephrasing it.",
                confidence=0.3,
                self_assessment="Error occurred - low confidence"
            )
    
    async def act(
        self,
        action: ActionType,
        action_input: str
    ) -> Observation:
        """
        åŸ·è¡Œè¡Œå‹•æ­¥é©Ÿ
        """
        if action == ActionType.FINAL_ANSWER:
            return Observation(
                content=action_input,
                sources=[],
                success=True,
                quality_score=0.8
            )
        
        if action == ActionType.CLARIFY:
            return Observation(
                content=f"Clarification needed: {action_input}",
                sources=[],
                success=True,
                quality_score=0.7
            )
        
        if action == ActionType.REFINE_QUERY:
            # å°‡ refine_query è½‰æ›ç‚º search
            action = ActionType.SEARCH
        
        # æŸ¥æ‰¾å·²è¨»å†Šçš„å·¥å…·
        tool_func = self.tools.get(action)
        if tool_func:
            try:
                result = await tool_func(action_input)
                
                # åˆ¤æ–·çµæœå“è³ª
                content = result.get("content", str(result))
                sources = result.get("sources", [])
                
                # ç°¡å–®çš„å“è³ªè©•ä¼°
                quality_score = 0.5
                if content and len(content) > 100:
                    quality_score += 0.2
                if sources:
                    quality_score += 0.1 * min(len(sources), 3)
                if "error" in content.lower() or "not found" in content.lower():
                    quality_score -= 0.3
                
                return Observation(
                    content=content,
                    sources=sources,
                    success=True,
                    quality_score=min(1.0, max(0.0, quality_score))
                )
            except Exception as e:
                logger.error(f"Tool execution error: {e}")
                return Observation(
                    content=f"Error executing {action.value}: {str(e)}",
                    sources=[],
                    success=False,
                    quality_score=0.0
                )
        
        return Observation(
            content=f"No tool registered for action: {action.value}",
            sources=[],
            success=False,
            quality_score=0.0
        )
    
    async def run(
        self,
        query: str,
        initial_context: str = "",
        enable_verification: bool = True
    ) -> ReActResult:
        """
        åŸ·è¡Œå®Œæ•´çš„ ReAct å¾ªç’° (Enhanced with PEV)
        
        Args:
            query: ç”¨æˆ¶æŸ¥è©¢
            initial_context: åˆå§‹ä¸Šä¸‹æ–‡ï¼ˆå¯èƒ½ä¾†è‡ªä¹‹å‰çš„ RAGï¼‰
            enable_verification: æ˜¯å¦å•Ÿç”¨ PEV é©—è­‰
        """
        steps: List[ReActStep] = []
        all_sources: List[Dict[str, Any]] = []
        accumulated_context = initial_context
        self.failed_attempts = []  # é‡ç½®å¤±æ•—è¨˜éŒ„
        
        logger.info(f"[ReAct] Starting loop for query: {query[:50]}...")
        
        for iteration in range(self.max_iterations):
            step_number = iteration + 1
            logger.info(f"[ReAct] Iteration {step_number}/{self.max_iterations}")
            
            # Step 1: Think
            thought_action = await self.think(query, accumulated_context, steps)
            
            step = ReActStep(
                step_number=step_number,
                thought=thought_action.thought,
                action=thought_action.action,
                action_input=thought_action.action_input
            )
            
            # å›èª¿é€šçŸ¥
            if self.on_step_callback:
                await self.on_step_callback(step)
            
            # Step 2: Act
            observation = await self.act(
                thought_action.action,
                thought_action.action_input
            )
            
            step.observation = observation.content[:1000]  # é™åˆ¶è§€å¯Ÿé•·åº¦
            
            # Step 3: Verify (PEV)
            if enable_verification and thought_action.action not in [ActionType.FINAL_ANSWER, ActionType.CLARIFY]:
                verification = await self.verify_observation(
                    query=query,
                    observation=observation,
                    step_context=accumulated_context[:500]
                )
                step.verification = verification
                
                # Step 4: Self-Correction if verification failed
                if not verification.is_valid or verification.quality_score < self.verification_threshold:
                    logger.warning(f"[ReAct] Verification failed (score={verification.quality_score}), attempting self-correction")
                    
                    # è¨˜éŒ„å¤±æ•—
                    self.failed_attempts.append({
                        "action": thought_action.action.value,
                        "input": thought_action.action_input,
                        "reason": "; ".join(verification.issues) if verification.issues else "Low quality"
                    })
                    
                    # å˜—è©¦ Self-Correction
                    if verification.should_retry and len(self.failed_attempts) < self.max_retries_per_step * self.max_iterations:
                        corrected_action = await self.self_correct(
                            query=query,
                            failed_action=thought_action.action,
                            failed_input=thought_action.action_input,
                            failure_reason="; ".join(verification.issues),
                            retry_strategy=verification.retry_strategy
                        )
                        
                        # ä½¿ç”¨ä¿®æ­£å¾Œçš„è¡Œå‹•é‡æ–°åŸ·è¡Œ
                        observation = await self.act(
                            corrected_action.action,
                            corrected_action.action_input
                        )
                        step.observation = f"[Corrected] {observation.content[:900]}"
                        step.thought = f"{step.thought} â†’ Corrected: {corrected_action.thought}"
            
            steps.append(step)
            all_sources.extend(observation.sources)
            
            # Step 5: Check if we should stop
            if thought_action.action == ActionType.FINAL_ANSWER:
                logger.info(f"[ReAct] Final answer reached at iteration {step_number}")
                
                # æ§‹å»ºæ¨ç†è»Œè·¡
                trace = self._build_reasoning_trace(steps)
                
                return ReActResult(
                    final_answer=observation.content,
                    steps=steps,
                    total_iterations=step_number,
                    sources=all_sources,
                    success=True,
                    reasoning_trace=trace,
                    verification_passed=True,
                    strategy_used="react_pev" if enable_verification else "react"
                )
            
            if thought_action.action == ActionType.CLARIFY:
                return ReActResult(
                    final_answer=observation.content,
                    steps=steps,
                    total_iterations=step_number,
                    sources=[],
                    success=True,
                    reasoning_trace=self._build_reasoning_trace(steps),
                    verification_passed=True,
                    strategy_used="clarification"
                )
            
            # Step 6: Update context with observation
            accumulated_context += f"\n\n[Search Result {step_number}]:\n{observation.content}"
            
            # å¦‚æœä¿¡å¿ƒè¶³å¤ é«˜ï¼Œæå‰çµæŸ
            if thought_action.confidence >= 0.85:
                logger.info(f"[ReAct] High confidence ({thought_action.confidence}), generating final answer")
                # å¼·åˆ¶ç”Ÿæˆæœ€çµ‚ç­”æ¡ˆ
                final_thought = await self.think(
                    query,
                    accumulated_context,
                    steps
                )
                if final_thought.action == ActionType.FINAL_ANSWER:
                    return ReActResult(
                        final_answer=final_thought.action_input,
                        steps=steps,
                        total_iterations=step_number,
                        sources=all_sources,
                        success=True,
                        reasoning_trace=self._build_reasoning_trace(steps),
                        verification_passed=True,
                        strategy_used="react_high_confidence"
                    )
        
        # é”åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•¸ï¼Œå¼·åˆ¶ç”Ÿæˆç­”æ¡ˆ
        logger.warning(f"[ReAct] Max iterations reached, forcing final answer")
        
        final_prompt = ChatPromptTemplate.from_template(
            """Based on all the information gathered, provide the best possible answer to the question.

Question: {query}

Gathered Information:
{context}

Provide a comprehensive answer based on available information. If information is incomplete, acknowledge this but still provide the best answer you can."""
        )
        
        chain = final_prompt | self.llm
        result = await chain.ainvoke({
            "query": query,
            "context": accumulated_context[:4000]
        })
        
        final_answer = result.content if hasattr(result, 'content') else str(result)
        
        return ReActResult(
            final_answer=final_answer,
            steps=steps,
            total_iterations=self.max_iterations,
            sources=all_sources,
            success=True,
            reasoning_trace=self._build_reasoning_trace(steps),
            verification_passed=len(self.failed_attempts) < 3,
            strategy_used="react_max_iterations"
        )
    
    def _build_reasoning_trace(self, steps: List[ReActStep]) -> str:
        """æ§‹å»ºå¯è®€çš„æ¨ç†è»Œè·¡"""
        trace_parts = []
        for step in steps:
            trace_parts.append(f"**Step {step.step_number}**")
            trace_parts.append(f"ğŸ’­ Thought: {step.thought}")
            trace_parts.append(f"ğŸ”§ Action: {step.action.value}({step.action_input[:100]}...)")
            if step.observation:
                trace_parts.append(f"ğŸ‘ï¸ Observation: {step.observation[:200]}...")
            if step.verification:
                v = step.verification
                status = "âœ…" if v.is_valid else "âŒ"
                trace_parts.append(f"ğŸ” Verification: {status} (score={v.quality_score:.2f})")
                if v.issues:
                    trace_parts.append(f"   Issues: {', '.join(v.issues[:2])}")
            trace_parts.append("")
        
        return "\n".join(trace_parts)


# å–®ä¾‹ç²å–
_react_loop_instance = None


def get_react_loop(
    max_iterations: int = 5,
    verification_threshold: float = 0.6
) -> ReActLoop:
    """ç²å– ReAct å¾ªç’°å¼•æ“å–®ä¾‹"""
    global _react_loop_instance
    if _react_loop_instance is None:
        _react_loop_instance = ReActLoop(
            max_iterations=max_iterations,
            verification_threshold=verification_threshold
        )
    return _react_loop_instance


def create_react_loop(
    max_iterations: int = 5,
    verification_threshold: float = 0.6,
    max_retries_per_step: int = 2,
    on_step_callback: Optional[Callable[[ReActStep], Awaitable[None]]] = None
) -> ReActLoop:
    """å‰µå»ºæ–°çš„ ReAct å¾ªç’°å¼•æ“å¯¦ä¾‹"""
    return ReActLoop(
        max_iterations=max_iterations,
        verification_threshold=verification_threshold,
        max_retries_per_step=max_retries_per_step,
        on_step_callback=on_step_callback
    )
